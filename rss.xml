<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Blog by Aslı Sabancı]]></title><description><![CDATA["Atoms with consciousness, matter with curiosity"]]></description><link>https://aslisabanci.github.io/blog</link><generator>GatsbyJS</generator><lastBuildDate>Fri, 07 Jan 2022 01:37:28 GMT</lastBuildDate><item><title><![CDATA[Building an automated workflow through Bitbucket and AWS components]]></title><description><![CDATA[In one of my projects, I built an automated workflow so that whenever an entity on Bitbucket gets updated through a push to a certain repository, some of the files in that repo would be transformed into different files by a serverless application on AWS.]]></description><link>https://aslisabanci.github.io/blog/posts/automated-workflow-bitbucket-aws</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/automated-workflow-bitbucket-aws</guid><pubDate>Sat, 30 May 2020 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;In one of my projects, I built an automated workflow so that whenever an entity on Bitbucket gets updated through a push to a certain repository, some of the files in that repo would be transformed into different files by a serverless application on AWS. This transformation creates some intermediary files which need to be processed by a containerized app. Finally, the output of this app would be stored again on AWS and the owner of the Bitbucket push request would be notified by email with a link to reach this output.&lt;/p&gt;
&lt;p&gt;Let’s briefly go over the connected parts and mention the AWS components I used to create this skeleton.&lt;/p&gt;
&lt;h2 id=&quot;automated-workflow&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#automated-workflow&quot; aria-label=&quot;automated workflow permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automated workflow&lt;/h2&gt;
&lt;p&gt;So, here’s what happens step-by-step:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Somebody makes a push on a Bitbucket repository.&lt;/li&gt;
&lt;li&gt;My Lambda function, sitting behind AWS API Gateway gets triggered by this push. This happens via the webhook that I set up on this Bitbucket repository.&lt;/li&gt;
&lt;li&gt;The Lambda function (i.e. the aforementioned “serverless application on AWS”) checks out this repository from Bitbucket as it needs to access the files in there. After getting those files, it performs certain transformations on certain files and creates some artifacts.&lt;/li&gt;
&lt;li&gt;When the Lambda function successfully creates these intermediary files, it sends a message to SQS.&lt;/li&gt;
&lt;li&gt;This SQS message triggers a batch job on AWS Batch.&lt;/li&gt;
&lt;li&gt;The batch job is set up to fire up a container using a specified Docker image on ECR, to start the aforementioned “containerized app”.&lt;/li&gt;
&lt;li&gt;This containerized app takes the intermediary files as its input, does its job on them and when its successfully finished, notifies the owner of the Bitbucket push in step number 1.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;cicd-workflow-for-my-own-deployment-automation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#cicd-workflow-for-my-own-deployment-automation&quot; aria-label=&quot;cicd workflow for my own deployment automation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CI/CD workflow for my own deployment automation&lt;/h2&gt;
&lt;p&gt;During the development of this skeleton, I also developed a CI/CD workflow for my own deployment automation. Whenever I made changes on my code, I wanted two things to happen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My Lambda function gets updated and re-deployed&lt;/li&gt;
&lt;li&gt;My Docker image gets re-pushed to ECR
so that the Lambda function and the “containerized app” of this workflow reflect the latest changes on my app code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My code repository was also sitting on Bitbucket. So, what I did was:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Whenever I make a push to my repository, my whole repository gets copied to a folder on AWS S3.  &lt;/li&gt;
&lt;li&gt;I set up AWS CodeBuild to automatically build this app folder.&lt;/li&gt;
&lt;li&gt;Then I connected CodeBuild with AWS CodeDeploy to re-deploy my Lambda functions and the built Docker image on ECR.
Doing these two deployments manually is a huge hassle after every code change and not-doing this automation would be a very inefficient use of my time. So building this CI/CD for myself was absolutely a good investment.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Sounds fun, right? Well, at least it was for me. This integration surely gave me many headaches but these are the type of headaches that I quite enjoy. When I solve those headaches and finally see a component getting integrated with another one, I love that feeling of having solved a problem and I guess that’s a big part of why I love my profession.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Building an end-to-end machine learning pipeline as a microservice]]></title><description><![CDATA[In one of my projects, my work focused on building end-to-end machine learning pipelines for training and inference phases of a machine learning model. Head over to this post for diving into those, component by component.]]></description><link>https://aslisabanci.github.io/blog/posts/end-to-end-machinelearning-pipeline-microservice</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/end-to-end-machinelearning-pipeline-microservice</guid><pubDate>Sat, 30 May 2020 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;In one of my projects, my work focused on building end-to-end machine learning pipelines for training and inference phases of a machine learning model. While I was working on building the pipeline, the model was iteratively developed and optimized by my data scientist team mates in parallel. The project in general consisted of loosely coupled microservices. Our pipeline would be interacting with these services through messaging services of the AWS platform.&lt;/p&gt;
&lt;p&gt;During the model training phase, the pipeline would be used to preprocess and structure the data as per the taste buds of our machine learning model. Then, during the inference phase, the pipeline would get the input data; apply the same preprocessing and structuring steps; feed this input into the model; get its inference and make it available for other components’ digestion on this ecosystem.&lt;/p&gt;
&lt;p&gt;Let’s go over these pipelines, component by component:&lt;/p&gt;
&lt;h3 id=&quot;data-collection-and-enrichment&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#data-collection-and-enrichment&quot; aria-label=&quot;data collection and enrichment permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Collection and Enrichment&lt;/h3&gt;
&lt;p&gt;Our core proprietary data that was collected from different internal sources. Because of this, it needed standardization, normalization and some cleanup with respect to our domain experts’ knowledge. Along with these tasks, enriching this core with 3rd party providers’ data was one of the main and ongoing tasks of this project - as the core data kept getting updated and our enrichment ideas kept continuing.&lt;/p&gt;
&lt;p&gt;The scope of this component was:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluating 3rd party data providers with respect to their technical API specs&lt;/li&gt;
&lt;li&gt;Collecting data from the chosen providers through API requests or through custom processes like FTP deliveries&lt;/li&gt;
&lt;li&gt;Versioning and managing the updates on this continuously growing ground truth data&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;data-storage&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#data-storage&quot; aria-label=&quot;data storage permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Storage&lt;/h3&gt;
&lt;p&gt;Different components of our pipeline dealt with different types of data. Some of them were highly relational while some were highly unstructured and document-style. So, I used both relational and non-relational database systems for storage.&lt;/p&gt;
&lt;p&gt;Designing the relational data structure was an ongoing process and my main objective was to keep the data “simply-enough” structured; thus easy to maintain. While evaluating on which database system to use and how best to store the data, I kept discussing questions like these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What types of queries do we want to perform on this data?&lt;/li&gt;
&lt;li&gt;How often are we going to want to do this?&lt;/li&gt;
&lt;li&gt;What additions or updates can we foresee on this data?&lt;/li&gt;
&lt;li&gt;What’s our scaling needs?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;quantitative-and-qualitative-checks-on-data&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#quantitative-and-qualitative-checks-on-data&quot; aria-label=&quot;quantitative and qualitative checks on data permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quantitative and Qualitative Checks on Data&lt;/h3&gt;
&lt;p&gt;We had certain criteria on our minds, when evaluating whether to go with a 3rd party provider’s data or not. A few examples of these were as follows.&lt;/p&gt;
&lt;h4 id=&quot;quantitative-criteria&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#quantitative-criteria&quot; aria-label=&quot;quantitative criteria permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quantitative Criteria&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;How much of our data cannot be enriched by this provider’s data?&lt;/li&gt;
&lt;li&gt;Can the API perform as per our performance requirements?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;qualitative-criteria&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#qualitative-criteria&quot; aria-label=&quot;qualitative criteria permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Qualitative Criteria&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;When compared to similar data providers’ data, how similar/different/reliable is this data?&lt;/li&gt;
&lt;li&gt;How good is their technical support? How responsive is the provider?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;standardization-normalization-and-aggregation-of-data&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#standardization-normalization-and-aggregation-of-data&quot; aria-label=&quot;standardization normalization and aggregation of data permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standardization, normalization and Aggregation of Data&lt;/h3&gt;
&lt;p&gt;As mentioned in &lt;a href=&quot;#Data%20Collection%20and%20Enrichment&quot;&gt;Data Collection and Enrichment&lt;/a&gt;, our data was like a sink where the input was flowing through many different internal and external faucets. So, this multi-regional sink was one of the biggest beasts to tackle throughout our project.&lt;/p&gt;
&lt;h4 id=&quot;standardization&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#standardization&quot; aria-label=&quot;standardization permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standardization&lt;/h4&gt;
&lt;p&gt;We had different non-standardized representations of some data; that in fact represent the same entity. To determine our standardization algorithms and processes; I first worked together with our domain experts. After gathering some “business rules” from their side, I worked out the technical process of this standardization and made this step a part of our pipeline going forward.&lt;/p&gt;
&lt;h4 id=&quot;normalization&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#normalization&quot; aria-label=&quot;normalization permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Normalization&lt;/h4&gt;
&lt;p&gt;This should come as no surprise that the numerical features in our data were in many different ranges. Also, different providers would use different units for the data that we want to consolidate. So, normalization was an important part of our data preprocessing.&lt;/p&gt;
&lt;h4 id=&quot;aggregation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#aggregation&quot; aria-label=&quot;aggregation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Aggregation&lt;/h4&gt;
&lt;p&gt;For certain data, storing every single data point meant that we would require lots of storage and we indeed do not need that much granularity. For these cases, calculating meaningful mathematical aggregations and storing them was a better choice.&lt;/p&gt;
&lt;h3 id=&quot;deployment-of-the-pipeline&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#deployment-of-the-pipeline&quot; aria-label=&quot;deployment of the pipeline permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deployment of the pipeline&lt;/h3&gt;
&lt;p&gt;Our pipeline had a Docker image, so that it could be registered on ECR and run in an isolated fashion on our microservice ecosystem; while allowing for easy scaling.&lt;/p&gt;
&lt;h3 id=&quot;getting-input-at-inference-time&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#getting-input-at-inference-time&quot; aria-label=&quot;getting input at inference time permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting input at inference time&lt;/h3&gt;
&lt;p&gt;The containerized applications were listening to a specific queue on AWS SQS to get their input. Our machine learning model was able to digest batch input. Thus, for efficiency, the input messages on SQS contained bundled requests. It was the pipeline’s job to unbundle these; do the preprocessing steps separately for each input; and when all the processing is done, bundle the data into a ready-to-be-consumed format and feed this as a batch into our model.&lt;/p&gt;
&lt;h3 id=&quot;outputting-the-predictions&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#outputting-the-predictions&quot; aria-label=&quot;outputting the predictions permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Outputting the predictions&lt;/h3&gt;
&lt;p&gt;Our model’s predictions were to be consumed by other microservices on our ecosystem. Just like the input, this communication was also carried over AWS SQS messaging platform.&lt;/p&gt;
&lt;p&gt;As a final note; this project opened my eyes to the reality of building machine learning applications. I experienced that 90% of our project was about getting the training data right. Because of this, most of the effort is rightfully spent on this matter to get a high performing model in the end.&lt;/p&gt;
&lt;p&gt;Afterwards, when it’s time to put this application on production, the performance of the pipeline gets the spotlight. If our end-to-end pipeline could not complete the steps of enriching &amp;#x26; preprocessing the input data and getting the model’s inference in a timely manner, this would be a total showstopper. As Miles Davis puts it: &lt;em&gt;“Time isn’t the main thing. It’s the only thing.”&lt;/em&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My experiences as a Machine Learning Engineer]]></title><description><![CDATA[In my previous role as a consultant Machine Learning Engineer, I worked on a few different projects and all of them were quite fun in different ways!]]></description><link>https://aslisabanci.github.io/blog/posts/experience-machinelearning-engineer</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/experience-machinelearning-engineer</guid><pubDate>Sat, 30 May 2020 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;In my previous role as a consultant Machine Learning Engineer, I worked on a few different projects. Some of them were in-house; improving our internal workflows by connecting certain components end-to-end or creating a framework to standardize certain parts of our data science projects. Others were large scale client projects; building training and inference pipelines for machine learning models, putting them into production or creating an API to serve model predictions to outside consumers.&lt;/p&gt;
&lt;p&gt;For our client projects, I was a part of various teams. Working with uniquely talented data engineers, data scientists, domain experts, client side stakeholders and product managers, consultants from fellow consultancy firms and technical people of our 3rd party data providers was a huge bliss and a huge challenge at the same time. I gained valuable experiences and a good understanding of the cloud platforms and tools for productionizing and scaling data-intensive applications.&lt;/p&gt;
&lt;p&gt;The cloud platform tools I got familiar with throughout these experiences were AWS EC2, SQS, ECR, Batch, Athena, Glue, CodeBuild, CodeDeploy, CloudFormation, CloudWatch, Docker and PySpark.&lt;/p&gt;
&lt;p&gt;In the following posts, I’ll briefly share some of the applications I built. For confidentiality reasons, I surely will not enclose the details of them. However, I can still outline the scope from an engineering perspective and I hope they’ll convey a rough idea on what types of structures get built around a machine learning model to get it on production or how different cloud components can be tied together to produce automated workflows.&lt;/p&gt;
&lt;p&gt;So, enjoy!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://aslisabanci.github.io/blog/posts/end-to-end-machinelearning-pipeline-microservice&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Building an end-to-end machine learning pipeline as a microservice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://aslisabanci.github.io/blog/posts/serving-predictions-aws-lambda-gateway&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Serving a machine learning model’s predictions through AWS Lambda and API Gateway&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://aslisabanci.github.io/blog/posts/automated-workflow-bitbucket-aws&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Building an automated workflow through Bitbucket and AWS components&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Serving a machine learning model’s predictions through AWS Lambda and API Gateway]]></title><description><![CDATA[In one of my projects, I worked on persisting the periodic output of an already developed machine learning model after enriching it with some metadata and then serving this enriched output through an API on AWS API Gateway.]]></description><link>https://aslisabanci.github.io/blog/posts/serving-predictions-aws-lambda-gateway</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/serving-predictions-aws-lambda-gateway</guid><pubDate>Sat, 30 May 2020 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;In one of my projects, I worked on persisting the periodic output of an already developed machine learning model after enriching it with some metadata and then serving this enriched output through an API on AWS API Gateway.&lt;/p&gt;
&lt;p&gt;Let’s go into the details component by component:&lt;/p&gt;
&lt;h2 id=&quot;persistence-and-enrichment-of-the-model-output&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#persistence-and-enrichment-of-the-model-output&quot; aria-label=&quot;persistence and enrichment of the model output permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Persistence and enrichment of the model output&lt;/h2&gt;
&lt;p&gt;Our machine learning model was persisting its periodic output as a file on S3. The consumers of our model’s output needed not only the model’s predictions but also certain metadata along with it; so that they don’t need to perform any extra queries on their side; because speed was of essence as usual.&lt;/p&gt;
&lt;p&gt;In order to create a highly responsive API with minimum latency, we needed to make the served data ready ahead in time. To make the model output queryable as per the requirements, the application I built would&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read the output file on S3 and process it record by record&lt;/li&gt;
&lt;li&gt;Join it with some metadata retrieved from AWS Athena&lt;/li&gt;
&lt;li&gt;Store the consolidated records on AWS DynamoDB in a “ready to be served” structure&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;restful-api-on-aws-api-gateway&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#restful-api-on-aws-api-gateway&quot; aria-label=&quot;restful api on aws api gateway permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RESTful API on AWS API Gateway&lt;/h2&gt;
&lt;p&gt;Well, we only needed a GET endpoint for this purpose, so we had nothing special on this layer. We also deferred the request authentication to the Lambda function itself (for business reasons) so the API Gateway did not require much work to setup.&lt;/p&gt;
&lt;h2 id=&quot;request-authentication&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#request-authentication&quot; aria-label=&quot;request authentication permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Request authentication&lt;/h2&gt;
&lt;p&gt;We made use of Bearer tokens in the request headers to verify the incoming requests’ authentication. The Bearer tokens were JWT tokens and they would contain some information like which public key was used for their signature, when the token expires, etc.. We had these public keys stored on our systems so that we can first verify that an incoming token is indeed a valid token and it has not yet expired. After verifying the token, the Lambda function would decode this token, retrieve certain fields of the decoded structure and use these to query DynamoDB.&lt;/p&gt;
&lt;h2 id=&quot;serving-lambda-function&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#serving-lambda-function&quot; aria-label=&quot;serving lambda function permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serving Lambda function&lt;/h2&gt;
&lt;p&gt;After successfully verifying the requester’s authentication information, and fetching the related records from DynamoDB, our Lambda function would simply structure this data as per our requirements and return it to the caller.&lt;/p&gt;
&lt;h2 id=&quot;data-management&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#data-management&quot; aria-label=&quot;data management permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data management&lt;/h2&gt;
&lt;p&gt;We made use of the TimeToLive feature of DynamoDB to get rid of relatively old data that we don’t need for our purposes.&lt;/p&gt;
&lt;h2 id=&quot;service-discovery&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#service-discovery&quot; aria-label=&quot;service discovery permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Service discovery&lt;/h2&gt;
&lt;p&gt;Our API would be discovered by other microservices and for service discovery, we needed to have certain artifacts on certain locations. The artifacts gave our API consumers some information like which endpoints we’re exposing and at which addresses they can access our API on our dev / test / qa / pre-prod / prod environments.&lt;/p&gt;
&lt;h2 id=&quot;monitoring-dashboards&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#monitoring-dashboards&quot; aria-label=&quot;monitoring dashboards permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Monitoring dashboards&lt;/h2&gt;
&lt;p&gt;We meticulously monitored our latency and error metrics on CloudWatch and had alarms for certain cases to have our eyes on our API’s health and performance. We also created custom dashboards for monitoring how often some use-cases happen, as we could detect these by filtering our logs against certain log messages.&lt;/p&gt;
&lt;h2 id=&quot;api-documentation-using-openapi-30-specs&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#api-documentation-using-openapi-30-specs&quot; aria-label=&quot;api documentation using openapi 30 specs permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API documentation using OpenAPI 3.0 Specs&lt;/h2&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 62.5%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACzklEQVQ4y22STW8bVRSG/SO6gm6AVW3PjOfLH4mtkAq1KaKw4u8gKljCH2irikU3bUU3/IOqIJMWlKQiTu3mA9upEztp4nHGnvHM+OHccWoJwZVenTsj3ee+574n88NTnR9/sfnu6Ud88+gKd55cFX3It08+4PufPxF9zL3fHB5v3uLhnys8WDd58MKaS+3Xbe7XLe7+fo2Hz78mc6vs8NmSS7VqYdk6hplHL+QwRJqRxbQ0NjZfEkZjhqMzRv4Q7+JcJPuLIaNJn2nsAwnt9gGZJcPky+oKS5VlHNtFy+tksznyeY1cNk+hYFKvv+DNbpuXf7xid69Ns7XP9naLdueIE2+fOAlRq9s5JHOjWKTmuliug+PYFOVbqVAwyOXFqaGztbWVHkiShP9bSTK7BHbI1ByHVduhaNuUy+UUput6qlwuJ+ACjUYjPTCbzRZVwVWdzZLFRd1Ol4whB78olVkVl5VKJQUqkKZp0noWWy7a2Nik9WZf2t6Xuidv1cX3/X/BF0BNgJ+6RW4uV9F0I4UomJICm6ZJq9UkjkKCyZggCIimU2YKohz/BygHLYHeXr3O2kqNarmEKy5dcazcVeQZ/mq8Zu+thzeOJe2EYJpInS0UhDHym857h6boq/ISN2rLuJYpCefnbyjVtS3WXzV53ITnux69wTmdgcc7P+bd+FKyH0Vw8LeEokubNUn4c3FSKVdkFm10cW0Y0r607Jg29e0NfurVedZrcDQ8o302oD/xOAkvGExGHI+HnE59Dnu9ObAi43JbAnHEValUWkgX6Nxhi0c78OueT/f4jIOjIYenPu2+JxeEnPoJ5wEc908UUOeaDPJ1CWatWsM2rfTtlBwZqVKpyOtmi4m0NA4iwulc0yhOaxQnMtjzcToZCNC0LApGgTVp+aYAHQlEtavmT12moDs7O4y8IWEYEMcSQBSlii/rVFJXtX/c5x9xJtRkaLiZdgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/a8e940017854cd153fc63d0a3afef88e/8ac56/swagger_editor.webp 240w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/d3be9/swagger_editor.webp 480w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/e46b2/swagger_editor.webp 960w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/f992d/swagger_editor.webp 1440w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/882b9/swagger_editor.webp 1920w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/491cb/swagger_editor.webp 2200w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/a8e940017854cd153fc63d0a3afef88e/8ff5a/swagger_editor.png 240w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/e85cb/swagger_editor.png 480w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/d9199/swagger_editor.png 960w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/07a9c/swagger_editor.png 1440w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/29114/swagger_editor.png 1920w,
/blog/static/a8e940017854cd153fc63d0a3afef88e/821da/swagger_editor.png 2200w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/a8e940017854cd153fc63d0a3afef88e/d9199/swagger_editor.png&quot;
            alt=&quot;api-docs&quot;
            title=&quot;api-docs&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
    &lt;/span&gt;
I used The OpenAPI 3.0 specs for the technical documentation of our API, as it has become the de facto standard to specify what an API can do. &lt;a href=&quot;http://editor.swagger.io/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Swagger Editor&lt;/a&gt; is a great tool to do this, since it can dynamically validate your specs as you write through a beautiful GUI. If you haven’t adopted conforming to the OpenAPI specs for your APIs, go learn about it now - I’m sure you’ll love this standardization idea!&lt;/p&gt;
&lt;p&gt;For me, this project was so fun to work on. It had a few performance optimization challenges, while preparing the ready-to-be-served data and serving the output through our Lambda function. The satisfaction of overcoming those hurdles were directly proportional to the size of those challenges though!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[How to Filter AWS Lambda Log Messages for CloudWatch Dashboard Widget]]></title><description><![CDATA[If you want see the graph of your Lambda function's specific log messages' count and create a CloudWatch dashboard widget out of it, you can have this setup.]]></description><link>https://aslisabanci.github.io/blog/posts/filter-aws-lambda-logs</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/filter-aws-lambda-logs</guid><pubDate>Thu, 31 Oct 2019 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;If you want see the graph of your Lambda function’s specific log messages’ count and create a CloudWatch dashboard widget out of it, you can have this setup:&lt;/p&gt;
&lt;p&gt;Let’s have an example: Your Lambda function logs down a message like “Performed {x} operation for input {y}” and you want to watch when this happens, over a graph (widget) on a CloudWatch dashboard.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open up your dashboard and click on Add Widget -&gt; Query Results and then Configure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/d698c/widget.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAABiElEQVQoz31S2U7DQAzcD+aDQIh3jhf+gAoVhEQRSAVaoImiXmnuo9vcyZBZtH1Aaq2MbMvZtcezYjKZYD6fw7IsGIaB1WqFMAzh+z6CIFBgfAie9p4Hx3EgXNdFkiSI4xhRFKl4t9tBSqnAuCgK5Hmu/P+4KkuUvdcQvCTLMnWYfrvdKjDX/pjJvEb/Ias6ZGUDkaap6tS2rULXdSj7rjTGNNLebDZomkbljJMkRt10sP0Yw4dHPI9e4MUZBKkul0vFn1TqusZoNIJpmvuLZ7MZptMpqqpSlw6HQwwGdyiqGmsnwPnZKW6urxCmOYTuTmqckLTH47ESijkb2ra9p8gVEW37N+3rxzfeP6dY2S6cSEJQBILicCKCDdbrtRKEU1H5xWKhGLAJ2VBZWpxKfP2YMKy+XlQQnIyHKIDeoRaHMSnyGXEq/kcwJxij61mEAWQaqwaCBe6NRT2hPqhz1on/eVGUkFmBNKsQbEskst8hBTn0kI/lQQ/X87G0PVzeGzi5eMPtk4Vfkpn4bMieU54AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/8ac56/widget.webp 240w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/d3be9/widget.webp 480w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/e46b2/widget.webp 960w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/f992d/widget.webp 1440w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/bb429/widget.webp 1846w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/8ff5a/widget.png 240w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/e85cb/widget.png 480w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/d9199/widget.png 960w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/07a9c/widget.png 1440w,
/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/d698c/widget.png 1846w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/66e8b6a8c7638020957a83f0e93fbbbc/d9199/widget.png&quot;
            alt=&quot;widget&quot;
            title=&quot;widget&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select your log group, which should be like &lt;code class=&quot;language-text&quot;&gt;/aws/lambda/{your_lambda_name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Put in your query, which is the most exciting part. Below is an example when you want to count the stats of a specific operation for your case. If you want to count the total number of times that this log message appears, then omit the filter part where you filter for the specific operation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;fields @message
| filter @message like /operation for input/
| parse @message /\\[(?&amp;lt;level&gt;\\S+)\\]\\s(\\S+)\\s(\\S+)\\s(?&amp;lt;op_name&gt;\\S+) operation for input (?&amp;lt;input&gt;\\S+)/
| filter op_name == {op_name_you_want_to_watch}
| stats count(op_name) by bin(5m)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/95ac795620598a51db98d7caae11d0d8/d38ac/query.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 38.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABNklEQVQoz41S2W6DMBD0//9clYcmBQPG2JwlDRjMUQWma0dEfWjVrjSa8XpYjwEWRRxJkkBrha7vYCeL0Y4ew/gdA0bi68cVdV2jIpTNFU3ToCZUVYW2bcFeLxqn0wsZbugaA9MajB0NvA1YlwXruuBzXUmvnpdphh3p0IE8xIe2FKDve7A4KRHxEJlU0HEOJTTSJEUmUpS5hs4kZMyRhhKpyKCFQp4WKGSBMlME8kiN97ryKVkchV4IIaBpQFEWCMIQnHPkee775/MZb0GAC5cQ7mDyKXpFSmsP7VgpD2ZuLT1EiWSGha647/sT27Z5fpbvb77/E5yXTfNMg2bMxPf73W8cfMCtH/h92OFjwzDgr9rxv/IDjTGYpsn/EtZarw926R279E5bSz33ld3e9NAHO49L+QV34mP3CR+gPgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/95ac795620598a51db98d7caae11d0d8/8ac56/query.webp 240w,
/blog/static/95ac795620598a51db98d7caae11d0d8/d3be9/query.webp 480w,
/blog/static/95ac795620598a51db98d7caae11d0d8/e46b2/query.webp 960w,
/blog/static/95ac795620598a51db98d7caae11d0d8/f992d/query.webp 1440w,
/blog/static/95ac795620598a51db98d7caae11d0d8/7e696/query.webp 1744w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/95ac795620598a51db98d7caae11d0d8/8ff5a/query.png 240w,
/blog/static/95ac795620598a51db98d7caae11d0d8/e85cb/query.png 480w,
/blog/static/95ac795620598a51db98d7caae11d0d8/d9199/query.png 960w,
/blog/static/95ac795620598a51db98d7caae11d0d8/07a9c/query.png 1440w,
/blog/static/95ac795620598a51db98d7caae11d0d8/d38ac/query.png 1744w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/95ac795620598a51db98d7caae11d0d8/d9199/query.png&quot;
            alt=&quot;query&quot;
            title=&quot;query&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run your query and if all looks fine, also check the Visualization.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then create your widget and enjoy watching your graph.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My Strategy For Getting My Google Cloud Professional Data Engineer Certification]]></title><description><![CDATA[Google's Professional Data Engineer certification exam is said to be difficult. I didn't believe it much until I took the exam myself. Now I also confirm that it's indeed a difficult exam and I don't think it can be achieved without thorough preparation and a solid engineering mindset.]]></description><link>https://aslisabanci.github.io/blog/posts/prep-strategy-google-data-engineering</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/prep-strategy-google-data-engineering</guid><pubDate>Sun, 11 Aug 2019 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;Google’s Professional Data Engineer certification exam is said to be difficult. I didn’t believe it much until I took the exam myself. Now I also confirm that it’s indeed a difficult exam and I don’t think it can be achieved without thorough preparation and a solid engineering mindset.  &lt;/p&gt;
&lt;p&gt;I wanted to share my own preparation strategy and do this as plainly as possible; with a very little amount of sugar-coated sentences.&lt;/p&gt;
&lt;h2 id=&quot;make-your-plan&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#make-your-plan&quot; aria-label=&quot;make your plan permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Make your plan&lt;/h2&gt;
&lt;p&gt;Think of for how long do you want to prepare for the exam. How exactly are you going to implement this plan, considering your daily and weekly schedule?&lt;/p&gt;
&lt;p&gt;Set overall and weekly goals for your target stages. Review this plan as needed. As you prepare, you will come across new material that you want to go through. Fitting these new items into your plan will shift things.&lt;/p&gt;
&lt;p&gt;Setting timed goals will let you set aside dedicated time for your goal. As you know, interesting new things to do always pop up in life. When you have scheduled goals, you will evaluate your how you use your time, keeping your goals in mind. If doing that interesting new thing instead means postponing your targeted time for your goal, then you would evaluate this opportunity cost and make an informed decision.&lt;/p&gt;
&lt;h2 id=&quot;follow-the-courses&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#follow-the-courses&quot; aria-label=&quot;follow the courses permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Follow the courses&lt;/h2&gt;
&lt;p&gt;All the existing blog posts about how to prepare for this certification already mention the following courses. Here’s what I think about them:&lt;/p&gt;
&lt;h3 id=&quot;google-clouds-own-course-set-on-coursera&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#google-clouds-own-course-set-on-coursera&quot; aria-label=&quot;google clouds own course set on coursera permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Google Cloud’s own course set on Coursera&lt;/h3&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/9eaa0/coursera.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 49.583333333333336%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAABYElEQVQoz42Ryy9DQRTG509CIuIR1SohHiVUsWApERsbiTalHteb0hLVEBILwl5ItP4aW8TM3HvTzWfOnU5br7ST/PKdnDNz7nfOZahyPmQBr28u3kUB1Y8Lls25yOY1Z7mymjj9ZCP5YCP1aJfunb/8TTbvgPnWOVpXONrXODpU3JzgCFiatlWOxjhH05JimaMloesNsU/URTX1RmMEBxvcFxjYEzDab2LF0IFA1yb3CCpmLiSmM9LLTxxLRNIS42lSgZDKhY8E2Mih8JKkkyfSYyyligrS7i3t1qcmmLuyEb93EL1zkHl2sXjrYOpUYv7axsKNjdlLGyyknIyqzsNJrdSYvk5x5waH3yqvgFZCUI5cUxyouEPKyL5xQ5B1M6rf+t6wEv8PNXgj0+zkKFykZ1u7CxZ3F7Bqh5V2p8Y0iyankZRuTvvt3RH/Ov3VsG+3/JdpXHpMBXJYSa0OvwA1jE3S8HNm4QAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/8ac56/coursera.webp 240w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/d3be9/coursera.webp 480w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/e46b2/coursera.webp 960w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/f992d/coursera.webp 1440w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/ab093/coursera.webp 1676w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/8ff5a/coursera.png 240w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/e85cb/coursera.png 480w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/d9199/coursera.png 960w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/07a9c/coursera.png 1440w,
/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/9eaa0/coursera.png 1676w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/bc1a94e55340315c7b70f0e5ffabf7cd/d9199/coursera.png&quot;
            alt=&quot;coursera&quot;
            title=&quot;coursera&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I watched the video courses and I did the labs. Thinking back now, I could have progressed faster with these. Maybe do only a few labs to get a feeling of the Google Cloud platform, and skip most of them. Most labs contain repetitive tasks and I don’t think there was a need to repeatedly do them for the purpose of exam preparation.&lt;/p&gt;
&lt;p&gt;I did the quizzes too. Besides the last course’s longer quiz, which is supposed to serve as a practice exam, they were very easy. So, they were useless and they could have been prepared way better, to be more “teaching” (I wonder if there’s a better word for this).&lt;/p&gt;
&lt;h3 id=&quot;linux-academy&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#linux-academy&quot; aria-label=&quot;linux academy permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux Academy&lt;/h3&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/5dae5d2425e9284ec0117456913775d4/a6ec4/linuxacademy.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 65.83333333333333%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACsklEQVQ4y32S20sUYRiH90+o2+qmoiAIuiiCCioowssICooglG7qInQhrDAosi46kEVISGaSEBqhmYLtIRXXTXd0D666ZZ5zzcWZPbg7e5hdfZpvdJcFo4GH9/vemff3ze99P9OyLDMW+IGihPm9ECS4uIimaYhnbW1tE8X5fz2mVCqFEI3H40RjMWKxFXK53KbC/wkXY8pkMoWXmXR6Peo5QVrfiygOFX8tyGazRhQ5cXD+2zwmr9eLxWIxkCQJu93OwMAADocDm81GT08PTqfTyAt6e3sN+vr6sFqtuqNY4VCBye320NraRvuXDjweLwk1SSIhUA3iIhq5BEm9QESBqqpGm/JCBUEtrZJSI2QzcbR0nNVsglVtfZ3VVH2vktNjJpMmGlb0omTBnrCeb4tYG5bHpxT6fTLSmIxrVMbiDPLV+YdBv8zIhMLgyDIuf4jISgpv1yfkpSCS28237m6+663p01vjcrmQ9cFGIhFMpQ/mOHBlhkNlC9x/Wsv7pnvcrfnArZpOdp39xfZTPnafn8QTiDEyPIgSUlhN6vaiKySjMcKyQjgcNjAEyyon2HvmJ1XVjUhDbxgbn8baUU/5ozqO3Qhy4tkCO476sXiXaJED1M+M0DAn8PPu9yghdUVvUZaMtjHla7d/svXwEM1tzdjGEszOzzMfgv3XI+w6PcnOklG27eunXZrjTsBGhdtKxVAXZo8Vs9fKVGSZnC6UzA/lavk4Jy97cNoraXhZzcPHLny+HrqbS3hR/ZybVUscPC4hDS/rt1VDFXb1QRhsiKQ31iKaLpb5uVTqw2xu4dwFK011t1h0HaHrbRmdbQ5eNSps2SPhciuGYDK5XlhMXswQ/NYb4unLKWrfhvj4eRH/sIPpwCC1jVHqmmSevJ6lpn6e4JJ+jbLpgrViikX/Aidkk3s1XZSWAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/5dae5d2425e9284ec0117456913775d4/8ac56/linuxacademy.webp 240w,
/blog/static/5dae5d2425e9284ec0117456913775d4/d3be9/linuxacademy.webp 480w,
/blog/static/5dae5d2425e9284ec0117456913775d4/e46b2/linuxacademy.webp 960w,
/blog/static/5dae5d2425e9284ec0117456913775d4/e12b1/linuxacademy.webp 1438w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/5dae5d2425e9284ec0117456913775d4/8ff5a/linuxacademy.png 240w,
/blog/static/5dae5d2425e9284ec0117456913775d4/e85cb/linuxacademy.png 480w,
/blog/static/5dae5d2425e9284ec0117456913775d4/d9199/linuxacademy.png 960w,
/blog/static/5dae5d2425e9284ec0117456913775d4/a6ec4/linuxacademy.png 1438w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/5dae5d2425e9284ec0117456913775d4/d9199/linuxacademy.png&quot;
            alt=&quot;linuxacademy&quot;
            title=&quot;linuxacademy&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I didn’t watch most of the videos, as I felt like I did enough watching. I went through their &lt;a href=&quot;https://www.lucidchart.com/documents/view/0ca44a63-4ea4-4d78-8367-2465512d21be/1&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;data dossier&lt;/a&gt;. It is like the study notes of a hardworking student, so I found it quite useful.&lt;/p&gt;
&lt;p&gt;I did all their quizzes and practice exams, and they were relatively way better questions than Google’s. I did them over and over because from time to time I got different questions. So I did them until I’m comfortable with all the questions.&lt;/p&gt;
&lt;p&gt;I took screenshots of the questions that I either did wrong or did correct but felt like I may want to re-do them. I pasted these screenshots on my study document.&lt;/p&gt;
&lt;p&gt;Needless to say; but whenever I didn’t understand why I answered a question wrong, I went over the related documentation of that Google product. Deliberately learning from your mistakes is very important when you are trying to learn anything.&lt;/p&gt;
&lt;p&gt;I went through the study cards of peer students on Linux Academy’s platform. Again, I took the screenshots of the cards that I want to go over again and pasted them on my study document. By the way, not all the things written on the study cards were correct. Don’t forget that these are prepared by peers who are also studying for the certification. So, take them with a grain of salt. When you feel uneasy about something you read, double-check it against the documentation.&lt;/p&gt;
&lt;h2 id=&quot;dive-deep-into-google-documentation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#dive-deep-into-google-documentation&quot; aria-label=&quot;dive deep into google documentation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dive deep into Google Documentation&lt;/h2&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/d4040846633afaa3eb00d864d266b97c/f8836/documentation1.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 103.33333333333331%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAABYlAAAWJQFJUiTwAAACVElEQVQ4y4WUi7aiMAxF+f+f9CIqOMr7KYq52YEgM0udrBXa0rRJzkkatNejpFklRVFIVVXS973c73cZhsHU57fbzcayLG2OjuNoI2dQ1sE1O8s1ryVNUynUuGnb9ZKu68wI4/nS0Ryznh3MF2PntsHzKSr2MXnqj2maZJo35Pnasr3tfLt2Ceq6lqZp1etg0XXqvVVvTdOsh94d3MrWJuCgh+zql23l8XhIqw5R0idtbPm/vTiIk0T2+0jCMJTj8ShRFOl6L3le6IHeoucQl4T6H9vocJCDahQd1C43J2BpETIBs4cqMi0jEDib/Bt0TLNstn1M5oQ5RODMIw1g93w+W2RECKafcHo3/9cmSJKzJHphluVyuVz1wsbqkZTTNDPvc8S9/PyEmupR4jg2iEjVM1pJqap6DXfLqpePGzopQMFYaSY4pma3Z41lqh+jbwJWRZHbJd8k+HO5GHOkTRm4dxj2KBD2YJ+UYR4FbwtG94DKOgWcKGhSorWMtaVPh6V/PR1sSBEdVW8Lw9ii7GvZDCte3wRSqILT6aQEZm8xt5Qp0N1uZxrHiTX8/NLc/jIkAlKsFfOiKE2pBMZSYeFhuRNhY8z1FmHbdrYJPtuScJa77tURH0kh/ETbz9P4VNA4pfVoVUoNx5BmQfDsNe2rU06n2N5DUiL0sqwsNTdCiIz0IMRb0h7ZZQ0kdqGzNrM8b/h6+5KQ/v/StcImVdoI9lDew215OI4QRR0Cj5WNPf/jWjLeMQHYrEzpSAGDSW1FXa+GjEBRLHsUsuGoypriRn4BFgpkW9oNWe0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/d4040846633afaa3eb00d864d266b97c/8ac56/documentation1.webp 240w,
/blog/static/d4040846633afaa3eb00d864d266b97c/d3be9/documentation1.webp 480w,
/blog/static/d4040846633afaa3eb00d864d266b97c/e46b2/documentation1.webp 960w,
/blog/static/d4040846633afaa3eb00d864d266b97c/874e8/documentation1.webp 1214w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/d4040846633afaa3eb00d864d266b97c/8ff5a/documentation1.png 240w,
/blog/static/d4040846633afaa3eb00d864d266b97c/e85cb/documentation1.png 480w,
/blog/static/d4040846633afaa3eb00d864d266b97c/d9199/documentation1.png 960w,
/blog/static/d4040846633afaa3eb00d864d266b97c/f8836/documentation1.png 1214w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/d4040846633afaa3eb00d864d266b97c/d9199/documentation1.png&quot;
            alt=&quot;documentation1&quot;
            title=&quot;documentation1&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This was by far my best source to study for the exam. Yes, it is a bottomless pit. It doesn’t have boundaries. You don’t know how deep you should dive into. You don’t know when to stop. You don’t know which parts are important and which parts you can skip. So, you are by yourself and you will find the answers to these questions using your critical mind.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/7a7e207d2985612ebda9b8ae604f5051/df88b/documentation2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 37.083333333333336%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAAA+UlEQVQoz22QSXLEIAxFff9bJm3jEZCY3ZsfhO0OVcnilbB5QsNgKGDaCMvBsOTgfEA538jl/CDfMZfmqJ2hLYNIfEZM+eNLHCzHJm7awbKDD/HfB1M+sVbnMA7sXCsu9A8Kw2E9vpTGuBhoQ9gP3SqL1COJ4qhNPHtz+UJM5epQc4Z1CaWUlvSQ6oiCiFI51g5nncAh//H680Ds6xjUqgnGEg5tWpem7kr+XeO8q8fYta33tuvSthwhxIRhMwHjSiC+lkx1j8JzfqKPdeTV4VX5Xrieb7fzZP+DVHiNE8ZJYVJzjfMdFdS8tDvZkYzDzv/CrkXqojz4A+JpF2OuOVtoAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/7a7e207d2985612ebda9b8ae604f5051/8ac56/documentation2.webp 240w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/d3be9/documentation2.webp 480w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/e46b2/documentation2.webp 960w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/f992d/documentation2.webp 1440w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/d1098/documentation2.webp 1906w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/7a7e207d2985612ebda9b8ae604f5051/8ff5a/documentation2.png 240w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/e85cb/documentation2.png 480w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/d9199/documentation2.png 960w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/07a9c/documentation2.png 1440w,
/blog/static/7a7e207d2985612ebda9b8ae604f5051/df88b/documentation2.png 1906w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/7a7e207d2985612ebda9b8ae604f5051/d9199/documentation2.png&quot;
            alt=&quot;documentation2&quot;
            title=&quot;documentation2&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Besides the product pages, here’s what I read and re-read in minimum:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Best practices&lt;/li&gt;
&lt;li&gt;Scenarios&lt;/li&gt;
&lt;li&gt;Use cases&lt;/li&gt;
&lt;li&gt;Importing data into this product from other ecosystem products&lt;/li&gt;
&lt;li&gt;Exporting data out of this product into other ecosystem products&lt;/li&gt;
&lt;li&gt;Pricing comparison between related products&lt;/li&gt;
&lt;li&gt;Feature comparison of Google platform products against Hadoop ecosystem products&lt;/li&gt;
&lt;li&gt;For which scenarios it makes sense to prefer the Google solution&lt;/li&gt;
&lt;li&gt;For which it makes sense to do the contrary&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Again, I took screenshots of the sections I deemed important and pasted them on my study document. Copy-pasting screenshots is much faster than copy-pasting text. Also, it preserves the format and reading is a better experience.&lt;/p&gt;
&lt;h2 id=&quot;read-google-solutions-blog-posts&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#read-google-solutions-blog-posts&quot; aria-label=&quot;read google solutions blog posts permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Read Google Solutions Blog Posts&lt;/h2&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/e8814/gcpsolutions.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 97.50000000000001%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAADKUlEQVQ4y5VU2W7TQBT1hyHxPUg8wQNvFRII9Ym+tQ8VEkgVFRIg1tI1NFUrtSglNOkCVbolaRxncWyP17FnDrPEaSn7SOPxjO1zz7n3XBugEdizCRwvf0LIAdcZoNvrwbZt9Ps2ut0u2u02LMtS9/1+X+wtmKap9r7vQw7OuZpG3JhBd/smHq9SrO352KuUUFxbR7n8BbXakQLPATqdjgDpKaBWy0RbBPEIuQIYneLD6SbeVxkcESyOAgRBiDAMkWUZ/mVIoHwYNBUHsbikAZJYAkUKTM4gCBRoHv1PE1wDG4R4aJktQb+DTlfLkzmTq8xbxnMW8sLEKgMwufmBWX5v/E0O8wkUlgRTMHqyIQBlKVKmU8PEO4ZEZoypaTkZivsUPTdVL8SVMsK510h2tiE5sbCJrHYXzJxVjGlGsW3t4d7WJM7c8wuGOhrHbpNjaVcWh6mHSXEZtLgCWpjTgId3gM/XwUvXkNnr6p3J6gzGt6dhhb0LwFx/lgQ4OLVBQi3Bbp7DWlkUa0PJDN0WurV3cJsfQRMPXAjZbX7FTnMfSRgrYiNAWU3HceEOeshSilSUnxAHQRoJrw3EPoEfxLBEOvpCQSKeu56Lw4NDfNv/hnq9rhnm7C5XLE/BUjXDo48J5ncyDH0BdlABPzsC/40ff5CceyoHnC4kuDUTYXIx0hUV9nIfjIFMTYAJFfzSNyPb/MqkjGnA2Y0Q914QPN2Ite+ETG9pDmFp80LVVcDf+k/YyBc5tMwGiGurHGfirE98BJSq51eVDTuFqM6Qja+7o6PaT1U9Y4qtXsWUbShMLFe5z8HYJWAjiiK4rgvieQhkNWOi8vO/P4WfJMuePWwD1QbHIFDNBSZ/DnZftR8bMkkF40SyHjJ0Yg8NYo7cYeQVbdkZFnYSPN+MUTrSDIP5d7Bv3wCZfaL2pUGKhycxnpkUPtXt+ea4gNtr46O8G5ophznIUNjnmK8A5VMdPVpdRjA+hujtS7WvCFO/soSxKVe5lGOhvo77panLgFp7FFNsVepYL5+h3fPUGRG/+5NqFY4oWp4tR5xFgT/KWa11go2DTyKArvJ3QIn2Z9AMFjkAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/8ac56/gcpsolutions.webp 240w,
/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/d3be9/gcpsolutions.webp 480w,
/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/e46b2/gcpsolutions.webp 960w,
/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/f3c7c/gcpsolutions.webp 1392w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/8ff5a/gcpsolutions.png 240w,
/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/e85cb/gcpsolutions.png 480w,
/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/d9199/gcpsolutions.png 960w,
/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/e8814/gcpsolutions.png 1392w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/43c3785af7e8c5338cc2cc6aee0ce1b6/d9199/gcpsolutions.png&quot;
            alt=&quot;gcpsolutions&quot;
            title=&quot;gcpsolutions&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I read quite a few articles on &lt;a href=&quot;https://gcp.solutions/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Google’s Cloud Solutions Architecture Reference&lt;/a&gt; I found interesting, covering the GCP products of my interest. Some were migration stories, or performance improvement stories or integration stories between legacy and newer systems. I am interested in reading architecture articles in any case, so they broadened my horizon and I’m sure they somehow helped me with my understanding of the products.&lt;/p&gt;
&lt;h2 id=&quot;listen-to-google-cloud-platform-podcast&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#listen-to-google-cloud-platform-podcast&quot; aria-label=&quot;listen to google cloud platform podcast permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Listen to Google Cloud Platform Podcast&lt;/h2&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 960px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/a2ef2/podcast.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 70.41666666666667%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAADYklEQVQ4y1WR609bZRzHT/wPTHxjfKOYmHnpqBo3nSuZkAHzNjeN7AWZ0SzOEcNluJKQbJmgoBjiJsNNlBUERzvKrVsLS4yL8QXxDYlhY6xXeoVCL6ellLa0/fick6Hsl3zyO8/3+zzf5/zOkcoqr1D5Zh+vVxnYV9mv8trBfp7b+yO7Xull154diLWia3U/Ubr/CtqyPl56tZcn9H/z6Hiaxz+7jVT6hpEXqscoPWAUG69R+gCtbuQBO59HVG/3/ofRHDDxfPmoyDAhaXRGdO9OsK/azMvlJvZUXOfpF3+lREE7yJOlAzyloN3ug6qvdFUTlAi9ZLdB7ZLZ4sIy7cc248Nq8zJxcwnTlJvrEw7MliUsM0EmbH7MN3xMTgcYF75x3C40sbYKhDcm+rjVy5jFg2RfWeLC2CDnrVPobTcx/mFl9q9pUsUMi3MzXOg+h2XgMnO3f2HM0Mns7zaUsoz2M2UZYXLiN/68NYp1ahin8y7SzA0zX35ey2MNeh5paeOjtrOYLn2FI5Kgv0tPbbWWTyt0dDRWcfqwhs6GOjLpTbpa66n98AjHDr9DR9NJTtS8zdCAGHl60syl1lNoGhp5pv1bjuvP0NvVTjiaoK/9DO2flPNFzXt06o8y1HSIyyJIqdlbI3Q119Le9jWNzS18/P5BLCYD0tA1I4afr3K+pxdNfSOtZ8/R3X0Rr9fP8MUO6o5XcerIW3zXcpSaimc53dSgBl79pp6eujK+/6GHE8cO0fzBXqZMw0ixaBSnx8e8fZXZeTcLrgB+n49sNkssssZqOMS9hXk8rjt43Q6CoSCFQpGgz8Va0MeCYw7n/X9wLd4R3gpSNldATmSIxNLk8zxU66kcsXgGOblFdut/XQmMJ3IqCXF2Z0mR6AZ374VxuCIq4dV10ps51fT5ZRbta7g8Ue471vD646TTOfKFgtBXVW3bj8tpMdUWkpzYFEExgsvrrIQ3WF5JsZUvqoFrkRS+QJzNTE7dvJHOksvlxSQFAiFZnEng9cXESyTFRVlxUREpkUiJW/x4lkJExfeMRCLIskxRZC4vL+NwOPC43Xg8HoLBgBhXCczjcrlVvF4vgUCAUDCo6pIsx3E67ITDK/8FKr0oElOplBqukEwm1QOKXhAjy/G4qis/T9G2vX8BMRhY/rzsxzYAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;picture&gt;
          &lt;source
              srcset=&quot;/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/8ac56/podcast.webp 240w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/d3be9/podcast.webp 480w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/e46b2/podcast.webp 960w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/f992d/podcast.webp 1440w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/882b9/podcast.webp 1920w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/b9178/podcast.webp 1970w&quot;
              sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
              type=&quot;image/webp&quot;
            /&gt;
          &lt;source
            srcset=&quot;/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/8ff5a/podcast.png 240w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/e85cb/podcast.png 480w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/d9199/podcast.png 960w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/07a9c/podcast.png 1440w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/29114/podcast.png 1920w,
/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/a2ef2/podcast.png 1970w&quot;
            sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
            type=&quot;image/png&quot;
          /&gt;
          &lt;img
            class=&quot;gatsby-resp-image-image&quot;
            src=&quot;/blog/static/28d210ed928c4f1a2f6a55f6bee31e33/d9199/podcast.png&quot;
            alt=&quot;podcast&quot;
            title=&quot;podcast&quot;
            loading=&quot;lazy&quot;
            style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
          /&gt;
        &lt;/picture&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I either bike to work or take the bus. Either way, my commutes are a good opportunity to listen to podcasts. I listen to them at home when my hands are busy but my ears are not.&lt;/p&gt;
&lt;p&gt;I subscribed to the &lt;a href=&quot;https://www.gcppodcast.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;GCP podcast&lt;/a&gt; and until I took the exam, whenever I had the chance to listen to something, I preferred to listen to something related to GCP. This meant that for this period I couldn’t listen to my beloved Planet Money or Bullseye. So for the sake of focusing, I made this sacrifice.&lt;/p&gt;
&lt;h2 id=&quot;listen-to-data-engineering-podcasts-covering-gcp-products&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#listen-to-data-engineering-podcasts-covering-gcp-products&quot; aria-label=&quot;listen to data engineering podcasts covering gcp products permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Listen to Data Engineering Podcasts covering GCP products&lt;/h2&gt;
&lt;p&gt;I have subscriptions to a few podcasts covering data engineering and machine learning engineering topics. I listened to their episodes that were about the guests’ experience in using or migrating to a GCP product and how they incorporated it into their workflows, how they decided to use this product, what they achieved, what problems they had on the way, etc. Listening to these helped me a lot in rather hard to describe ways I guess. For instance, sometimes the host or the guest says something that answers a question on your mind or something makes you curious about a topic, then you read on it and learn something that in turn improves your understanding about that topic.&lt;/p&gt;
&lt;h2 id=&quot;collect-and-manage-online-material&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#collect-and-manage-online-material&quot; aria-label=&quot;collect and manage online material permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Collect and manage online material&lt;/h2&gt;
&lt;p&gt;I created a bookmark folder and kept everything that I want to read in this folder. I created another folder to keep my read items. As I read the material, I moved it from the parent folder to this read items folder, because I didn’t want to remove the bookmark. Also moving the items from one folder to another somehow gives you a sense of progress. You may feel like you are doing good with your preparation goals.&lt;/p&gt;
&lt;h2 id=&quot;review-constantly&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#review-constantly&quot; aria-label=&quot;review constantly permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Review constantly&lt;/h2&gt;
&lt;p&gt;I exported this document with my pasted screenshots into a pdf and I put it on my phone. This way, whenever I had some time, I reviewed it easily. Waiting on the queue, waiting for my commute, my commute itself were all good opportunities.&lt;/p&gt;
&lt;p&gt;This document was very large. I didn’t feel like going over all of its parts at a given time. Sometimes I felt like reviewing the practice questions, sometimes the study cards and sometimes the screenshots from the Google documentation. So making the study document navigable with links was a good idea.&lt;/p&gt;
&lt;h2 id=&quot;find-free-practice-questions&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#find-free-practice-questions&quot; aria-label=&quot;find free practice questions permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Find free practice questions&lt;/h2&gt;
&lt;p&gt;You can find some sets of free practice questions here and there. Some of them are lame but you can benefit from some questions. The actual exam questions will be much more complex and harder but still, these will get your engines warm.&lt;/p&gt;
&lt;h2 id=&quot;prepare-mentally-for-the-difficulty&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#prepare-mentally-for-the-difficulty&quot; aria-label=&quot;prepare mentally for the difficulty permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prepare mentally for the difficulty&lt;/h2&gt;
&lt;p&gt;In my exam, around 10/50 questions were super easy, where you had the answer in 2 seconds. 20/50 questions were at a normal difficulty and pretty doable if you are comfortable with all the capabilities of the GCP products. The remaining 20/50 were quite tough and consumed more than half of my exam duration.&lt;/p&gt;
&lt;p&gt;Here, tough means that the question is describing a complex case and you are not sure if the given products have those claimed features in the options. In these cases, having an engineering perspective will be the best tool in your belt. For instance, when you are given an I/O bound performance problem, you would know that you shouldn’t solve it as if you are solving a CPU bound performance problem.&lt;/p&gt;
&lt;p&gt;For these tough questions, I can’t even formulate how to prepare. For instance, you cannot know every Hadoop product’s details in action as you mostly focus on the GCP products, or you cannot know every option to a command in the gcloud SDK. So, the best thing to do will be to stay calm and use your engineering mindset to put your best guess.&lt;/p&gt;
&lt;p&gt;So, embrace the fact that this exam will be much harder than all the practice questions you’ve done and you will read many forum posts from people failing the exam. Prepare yourself mentally, but don’t get demotivated. If you are properly prepared for the exam, focus on your inner strength and let your previous achievements be your spring of confidence for the things you will next achieve.&lt;/p&gt;
&lt;h2 id=&quot;enjoy-your-swag&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#enjoy-your-swag&quot; aria-label=&quot;enjoy your swag permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enjoy your swag!&lt;/h2&gt;
&lt;p&gt;One of the best parts of earning your certificate will be reading the email from Google, asking you to pick your well deserved swag from the Google Merchandise Store. I got myself a hoodie and whenever I wear it, its cuddlesome comfort gets combined with my inner comfort for achieving this.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Basic NN for the Avito Demand Prediction Competition on Kaggle]]></title><description><![CDATA[I wanted to try building a model for the Avito Demand Prediction competition on Kaggle and I came across a few hurdles on the road, which taught me lots of new things. I wasn't after a good score but I just wanted to build a neural network with Keras from end to end and get predictions from it.]]></description><link>https://aslisabanci.github.io/blog/posts/basic-neuralnet-avito-demand-prediction-competition-kaggle</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/basic-neuralnet-avito-demand-prediction-competition-kaggle</guid><pubDate>Thu, 28 Jun 2018 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;I wanted to try building a model for the Avito Demand Prediction competition on Kaggle and I came across a few hurdles on the road, which taught me lots of new things. I wasn’t after a good score but I just wanted to build a neural network with Keras from end to end and get predictions from it.&lt;/p&gt;
&lt;p&gt;So for this competition, we’re trying to predict demand for an online advertisement based on its full description (title, description, images, etc.) and its context.&lt;/p&gt;
&lt;p&gt;Roughly, I wanted to make use of the categorical features and a few continuous features. I also wanted to the features of the images and for this I wanted to get their extracted features from VGG16.&lt;/p&gt;
&lt;h2 id=&quot;getting-image-features-from-vgg16&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#getting-image-features-from-vgg16&quot; aria-label=&quot;getting image features from vgg16 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting image features from VGG16&lt;/h2&gt;
&lt;p&gt;While I was trying to get the image feature extraction through VGG16, I found out that someone else on Kaggle has a kernel for that, so I added his two kernels’ outputs (one outputting the VGG16 features of the training data set images and the other one, the test data set images) as the data source of my own kernel and I could use these sparse output matrices within my script.&lt;/p&gt;
&lt;p&gt;So I dropped the image column of the datasets and appended these 512 features taken from VGG16, to my train and test data frames (during feeding my model batch by batch, as explained below, because the dense array version of these sparse data was taking lots of memory).&lt;/p&gt;
&lt;h2 id=&quot;cleaning-imputing-dropping-transforming-encoding-scaling&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#cleaning-imputing-dropping-transforming-encoding-scaling&quot; aria-label=&quot;cleaning imputing dropping transforming encoding scaling permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cleaning, imputing, dropping, transforming, encoding, scaling&lt;/h2&gt;
&lt;p&gt;I dropped the columns I won’t use and imputed the datasets by filling in the NAN values accordingly. Then I transformed some features like the activation date to weekday and title and description (which were in Russian) to their word counts (I could have dealt with this information by extracting the text features through another established model, but I didn’t focus on that).&lt;/p&gt;
&lt;p&gt;I encoded the categorical columns with LabelEncoders and I scaled my continuous features between 0 and 1, using the StandardScaler.&lt;/p&gt;
&lt;h2 id=&quot;fitting-all-the-data-into-15gb-memory&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#fitting-all-the-data-into-15gb-memory&quot; aria-label=&quot;fitting all the data into 15gb memory permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fitting all the data into 15GB memory&lt;/h2&gt;
&lt;p&gt;Of course, as a noob, I took my chances to see if I can feed all of this data at once to my model. Apparently and indeed not surprisingly, this wasn’t possible with the Kaggle kernels’ 15 GB memory limit. Then I learnt about the fit_generator method of Keras, which lets you feed your data to your model, spoon by spoon :] I’m pretty happy that I learnt about this method - hurdles along the way are the best teachers I think.&lt;/p&gt;
&lt;h2 id=&quot;getting-nan-loss-during-training&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#getting-nan-loss-during-training&quot; aria-label=&quot;getting nan loss during training permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting NAN loss during training&lt;/h2&gt;
&lt;p&gt;During the initial steps, my loss value was decreasing but then I started getting NAN loss, before the 1st epoch completed. This made me suspicious of my input data and I found out that I forgot to scale some of my continuous features. I did that and these NAN values were gone.&lt;/p&gt;
&lt;h2 id=&quot;final-thoughts&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#final-thoughts&quot; aria-label=&quot;final thoughts permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Final thoughts&lt;/h2&gt;
&lt;p&gt;So this pretty basic model didn’t do super great in the competition but I at least succeeded in building an end to end model, getting its predictions and I learnt a lot from these small to medium scale hurdles :]
To improve this, I can think of what new features I can introduce with “feature engineering”, modify my hyper-parameters or my network architecture or make use of some more features like the description for instance.&lt;/p&gt;
&lt;p&gt;So here is my script but of course it won’t run properly unless you run it on a Kaggle kernel by adding the necessary datasets. If you spot any mistakes, you are more than welcome to point those out and let me learn from you!&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; np
&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;token keyword&quot;&gt;as&lt;/span&gt; pd
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; scipy &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; sparse
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; sklearn&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;preprocessing &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; StandardScaler
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; sklearn&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;preprocessing &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; LabelEncoder
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;models &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; Model
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;callbacks &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; EarlyStopping&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ModelCheckpoint
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;layers &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; Embedding&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; concatenate&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Flatten&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; Dropout&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; BatchNormalization
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; keras&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;optimizers &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; adam
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; keras &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; losses
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; keras &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; metrics


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	train_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;read_csv&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;../input/avito-demand-prediction/train.csv&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; parse_dates&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;activation_date&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;read_csv&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;../input/avito-demand-prediction/test.csv&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; parse_dates&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;activation_date&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;activation_date&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;expand_dims&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
		pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;to_datetime&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;activation_date&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;dt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;weekday&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;astype&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;int32&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;activation_date&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;expand_dims&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
		pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;to_datetime&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;activation_date&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;dt&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;weekday&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;astype&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;int32&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	y_col &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;deal_probability&apos;&lt;/span&gt;

	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y_col


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;fill_na&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;image_top_1&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3067&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;image_top_1&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3067&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;param_1&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;_NA_&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;param_1&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;_NA_&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;param_2&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;_NA_&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;param_2&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;_NA_&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;param_3&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;_NA_&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;param_3&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fillna&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;value&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;_NA_&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;drop_unwanted&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	train_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;drop&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;item_id&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;user_id&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;image&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;drop&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;item_id&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;user_id&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;image&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inplace&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;encode_cat_columns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;all_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	cat_cols &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;region&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;parent_category_name&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;category_name&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;city&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;user_type&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;image_top_1&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;param_1&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
	            &lt;span class=&quot;token string&quot;&gt;&apos;param_2&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;param_3&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

	le_encoders &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; LabelEncoder&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; x &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; cat_cols&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
	label_enc_cols &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;k&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; v&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit_transform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;all_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;k&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; k&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; v &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; le_encoders&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;items&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; le_encoders&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; label_enc_cols


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;transform_title_description&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;title&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;split&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;description&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;split&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;title&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;split&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;description&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;split&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;scale_num_cols&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	stdScaler &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; StandardScaler&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; stdScaler&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit_transform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; stdScaler&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit_transform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;test_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;load_VGG16_img_features&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	train_img_features &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; sparse&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_npz&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;../input/vgg16-train-features/features.npz&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	test_img_features &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; sparse&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_npz&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;../input/vgg16-test-features/features.npz&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; train_img_features&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_img_features


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;split_train_validation&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	val_split &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.15&lt;/span&gt;
	val_ix &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;np&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;rint&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; val_split&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	t_split_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;val_ix&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
	v_split_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; train_data&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;val_ix&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

	image_t_split_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; train_img_features&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;val_ix&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
	image_v_split_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; train_img_features&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;val_ix&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; t_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; v_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_t_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_v_split_df


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;gen_samples&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;in_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; img_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loss_name&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;

	samples_per_epoch &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; in_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
	number_of_batches &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; samples_per_epoch &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; batch_size
	counter &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;

	&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;

		&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; batch_size &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
			out_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; in_df

		&lt;span class=&quot;token keyword&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
			sub_img_frame &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;DataFrame&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;img_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;batch_size &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; counter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;batch_size &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;counter &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;todense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

			sub_img_frame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;columns &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;img_&apos;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;col&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; col &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; sub_img_frame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;columns&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

			out_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; in_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;batch_size &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; counter&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;batch_size &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;counter &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

			&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; col &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; sub_img_frame&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;columns&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
				out_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;insert&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;out_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;columns&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; col&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Series&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;sub_img_frame&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;col&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; index&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;out_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;index&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

		feed_dict &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;col_name&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; le_encoders&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;col_name&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;transform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;out_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;col_name&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; col_name &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; cat_cols&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

		cont_cols &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;x &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; x &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; out_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;columns &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;img_&apos;&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
		cont_cols&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;extend&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;price&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;item_seq_number&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;description&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
		feed_dict&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;continuous&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; out_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;cont_cols&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values

		counter &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;

		&lt;span class=&quot;token keyword&quot;&gt;yield&lt;/span&gt; feed_dict&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; out_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;loss_name&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values

		&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; counter &lt;span class=&quot;token operator&quot;&gt;&amp;lt;=&lt;/span&gt; number_of_batches&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
			counter &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;root_mean_squared_error&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;y_true&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y_pred&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; K&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;sqrt&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;K&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;mean&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;K&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;square&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;y_pred &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; y_true&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;build_model&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;label_enc_cols&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
	all_embeddings&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; all_inputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

	&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; key&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; val &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; label_enc_cols&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;items&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
		in_val &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; key&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
		all_embeddings &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;Flatten&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Embedding&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;val&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;val&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;in_val&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
		all_inputs &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;in_val&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;

	concat_emb_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; concatenate&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;all_embeddings&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	bn_emb &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; BatchNormalization&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;concat_emb_layer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	emb_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Dropout&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bn_emb&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	cont_input &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Input&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;shape &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;516&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; name &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;continuous&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	bn_cont &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; BatchNormalization&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;cont_input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	cont_feature_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Dropout&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;bn_cont&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	full_concat_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; concatenate&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;emb_layer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; cont_feature_layer&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	full_reduction &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;relu&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;full_concat_layer&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	out_layer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Dense&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; activation &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;sigmoid&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;full_reduction&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
	model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;inputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; all_inputs &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;cont_input&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; outputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;out_layer&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

	&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; model



train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y_col &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; load_data&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fill_na&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; drop_unwanted&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; transform_title_description&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

all_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;concat&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; sort &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
le_encoders&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; label_enc_cols &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; encode_cat_columns&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;all_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; scale_num_cols&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

train_img_features&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_img_features &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; load_VGG16_img_features&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

t_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; v_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_t_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_v_split_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; split_train_validation&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;train_data&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

model &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; build_model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;label_enc_cols&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; optimizers&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Adam&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;lr &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.0005&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; beta_1 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; beta_2 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; epsilon &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; decay &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; amsgrad &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;optimizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; optimizer&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; root_mean_squared_error&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; metrics &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;root_mean_squared_error&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

checkpoint &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ModelCheckpoint&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;best_weights.hdf5&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; monitor &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;val_loss&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; verbose &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; save_best_only &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
early &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; EarlyStopping&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;patience &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; mode &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;min&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

batch_size &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;64&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit_generator&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;gen_samples&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;t_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_t_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y_col&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                    epochs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                    steps_per_epoch &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; t_split_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; batch_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                    validation_data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;gen_samples&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;v_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; image_v_split_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; y_col&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                    validation_steps &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
                    callbacks &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;checkpoint&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; early&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

test_vars&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_id &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;gen_samples&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;test_data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_img_features&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; loss_name &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load_weights&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;best_weights.hdf5&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
preds &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; model&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;test_vars&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

subm &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;read_csv&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;../input/avito-demand-prediction/sample_submission.csv&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
subm&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;deal_probability&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; preds
subm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;to_csv&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;submission_adam.csv&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; index&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[How to setup your Kaggle environment on Google Colab]]></title><description><![CDATA[Not a biggie, but I wanted to share my little Jupyter notebook on my github repo, which you can just copy and have your Kaggle environment quickly set up on Google Colab.]]></description><link>https://aslisabanci.github.io/blog/posts/setup-kaggle-env-on-colab</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/setup-kaggle-env-on-colab</guid><pubDate>Sat, 16 Jun 2018 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;Not a biggie, but I wanted to share my little Jupyter notebook on &lt;a href=&quot;https://github.com/aslisabanci/kaggle_colab&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;my github repo&lt;/a&gt;, which you can just copy and have your Kaggle environment quickly set up on Google Colab.&lt;/p&gt;
&lt;h2 id=&quot;get-your-things-ready&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#get-your-things-ready&quot; aria-label=&quot;get your things ready permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get your things ready💼&lt;/h2&gt;
&lt;p&gt;First sign up for &lt;a href=&quot;https://colab.research.google.com/notebooks/welcome.ipynb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Google Colab&lt;/a&gt; (which is for free).&lt;/p&gt;
&lt;p&gt;Then go ahead and get your API token from your &lt;a href=&quot;https://www.kaggle.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Kaggle&lt;/a&gt; account. You will find this under your Profile &gt; Account section. Kaggle will create a JSON file and you’ll download it on your machine.&lt;/p&gt;
&lt;h2 id=&quot;run-the-commands-on-the-notebook♀️&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#run-the-commands-on-the-notebook%E2%99%80%EF%B8%8F&quot; aria-label=&quot;run the commands on the notebook♀️ permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run the commands on the notebook🏃‍♀️&lt;/h2&gt;
&lt;p&gt;Create a notebook or just copy mine and there you can run these commands to install the Kaggle framework. After that, handle the authentication between Google Colab and Kaggle and start using the Kaggle API to list / search competitions / datasets, download the data on your virtual machine.&lt;/p&gt;
&lt;h2 id=&quot;enjoy🤸♀️&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#enjoy%F0%9F%A4%B8%E2%99%80%EF%B8%8F&quot; aria-label=&quot;enjoy🤸♀️ permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enjoy🤸‍♀️&lt;/h2&gt;
&lt;p&gt;After you have your data ready, install the frameworks you need on your virtual machine and take off with your machine learning adventures, running on Google’s GPUs for free.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Generating random Turkish first names with a super basic RNN]]></title><description><![CDATA[Inspired by the mini 'Dinosaur name generator' project I did a while ago, I wanted to re-use the core code (with some modifications and refactorings of my own) and try to generate Turkish first names. The project was about building a simple recurrent neural network using numpy and it was a part of the Sequence Models course of Andrew Ng's awesome Deep Learning Specialization series on Coursera.]]></description><link>https://aslisabanci.github.io/blog/posts/generating-random-turkish-names-with-rnn</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/generating-random-turkish-names-with-rnn</guid><pubDate>Wed, 06 Jun 2018 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;Inspired by the mini “Dinosaur name generator” project I did a while ago, I wanted to re-use the core code (with some modifications and refactorings of my own) and try to generate Turkish first names. The project was about building a simple recurrent neural network using numpy and it was a part of the Sequence Models course of &lt;a href=&quot;http://deeplearning.ai/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Andrew Ng’s awesome Deep Learning Specialization series on Coursera&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;main-flow&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#main-flow&quot; aria-label=&quot;main flow permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Main Flow&lt;/h2&gt;
&lt;p&gt;The project builds a simple character level language model to generate new first names. Roughly, the steps are to:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the weights&lt;/li&gt;
&lt;li&gt;Forward propagate and calculate the loss&lt;/li&gt;
&lt;li&gt;Backward propagate and calculate the gradients, using the loss&lt;/li&gt;
&lt;li&gt;Clip the gradients with a max value, so that they don’t explode&lt;/li&gt;
&lt;li&gt;Update the weights using the gradients&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The input we provide is the list of characters of each name in the dataset; and the output at every time step is the next character to be used. At each time step, our recurrent neural network is picking a character, given the previous character, according to a probability distribution.&lt;/p&gt;
&lt;h2 id=&quot;preprocessing-the-data&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#preprocessing-the-data&quot; aria-label=&quot;preprocessing the data permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preprocessing the data&lt;/h2&gt;
&lt;p&gt;I wanted to try this model with two approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the most common 10 thousand names within the whole dataset (so that the dataset consists of unique names)&lt;/li&gt;
&lt;li&gt;Get 3 million names, regardless of their frequency (so that the frequent names appear more in the dataset)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For both approaches, I needed to clean the data first because some of the names contained characters like dot, paranthese, hyphen, number and what not.&lt;/p&gt;
&lt;p&gt;Also there were some non-Turkish names in the dataset, so I removed names that contain “x”, “w”, “q” as these letters are not in the Turkish alphabet.&lt;/p&gt;
&lt;p&gt;Lastly, there were a lot of first names consisting of two or three names. Since I didn’t want my model to generate names consisting of two or more names, I split these into single ones. While procesing the names one by one, I added a split name into my list of names, if it hasn’t been added in the earlier iterations.&lt;/p&gt;
&lt;p&gt;There were a lot of names with this style within my 10K and 3m dataset. So after reducing them to single names, I only ended up with ~700 and ~5000 distinct names respectively.&lt;/p&gt;
&lt;h2 id=&quot;getting-predictions&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#getting-predictions&quot; aria-label=&quot;getting predictions permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting predictions&lt;/h2&gt;
&lt;p&gt;I wanted to see how familiar the names will look, when trained with the most common Turkish names (10K dataset) and when trained with most of the names coming from the longer tail (3m dataset).&lt;/p&gt;
&lt;p&gt;So I took 10 different output samples from each model.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;10K dataset&lt;/th&gt;
&lt;th&gt;3m dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sin, Badir, Sedef, Akmul, Salan, Betad, Behan, Siga, Kanefi, Sac&lt;/td&gt;
&lt;td&gt;Bevit, Ezer, Kumul, Zarit, Semiye, Gursap, Hukdeye, Sevar, Tahiye, Ozar&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Vuran, Bahir, Urdi, Akir, Sam, Curec, Celkemi, Sula, Kari, Saba&lt;/td&gt;
&lt;td&gt;Goley, Niyur, Menan, Apmat, Mindorlah, Azda, Sulki, Guka, Kime, Ergi&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Radugi, Dukdur, Maha, Zusuf, Mayih, Nefah, Aysu, Selsem, Gabsun, Kahat&lt;/td&gt;
&lt;td&gt;Zuraye, Rettime, Sengelli, Gulcime, Sortedi, Sugon, Zaki, Memra, Kunni, Hucan&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bercan, Habbat, Nultan, Ayiz, Yurev, Havgi, Bakes, Yaydil, Melif, Kalis&lt;/td&gt;
&lt;td&gt;Gungu, Aybeden, Yavrun, Samine, Ruydar, Arnur, Hazti, Vuteton, Cahan, Talize&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Baytul, Sicen, Ekep, Ale, Murgal, Kerif, Furem, Zihan, Kubza, Luse&lt;/td&gt;
&lt;td&gt;Tekayu, Cabilatviye, Feyhan, Badabed, Sasir, Gugiki, Guhteviz, Sehhun, Sakser, Edana&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Becer, Hase, Gahat, Betri, Sidar, Erzan, Gulsul, Benan, Kevay, Efere&lt;/td&gt;
&lt;td&gt;Uzatil, Iren, Buhneyan, Sefdan, Vezhap, Fimnan, Bikan, Hirdar, Havdin, Hadrure&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Suray, Bali, Guhan, Sele, Bezih, Zaza, Zacet, Saya, Dasen, Sevdam&lt;/td&gt;
&lt;td&gt;Kurt, Iyarlan, Kagiy, Kiysan, Samay, Bervan, Safi, Fur, Zetir, Biheti&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Beyfa, Fahat, Dula, Zatkun, Semelten, Gondur, Gulerun, Buysut, Gukpek, Alpfehatengel&lt;/td&gt;
&lt;td&gt;Gocdan, Buhac, Sabip, Belet, Iben, Buhise, Aran, Semum, Sencin, Ceni&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aseye, Emra, Fera, Oyas, Zumul, Azel, Fular, Guli, Saner, Fasi&lt;/td&gt;
&lt;td&gt;Urman, Erikmar, Buhan, Rahif, Hadul, Rosen, Daban, Hana, Rani, Zizasel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cevli, Seylut, Sayih, Gece, Kaki, Dilsin, Semi, Aser, Sabil, Boylu&lt;/td&gt;
&lt;td&gt;Heri, Soket, Serme, Selzikcan, Nurlay, Harfir, Seyyulga, Zeyar, Dilal, Gunsan&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;my-thoughts&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#my-thoughts&quot; aria-label=&quot;my thoughts permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;My thoughts&lt;/h2&gt;
&lt;p&gt;For me, the results when the model is trained with the 10K dataset sound more familiar. Probably that’s because I only heard a certain amount of Turkish names in my lifetime and when looking at the whole dataset, there are many many names which feel weird / funny to me :) Naturally, these types of weird sounding Turkish names are more present in the 3m dataset, so what my model generates may sound more like them.&lt;/p&gt;
&lt;p&gt;Also what made me happy is that all the generated names are at least pronouncible in Turkish. Normally in Turkish, no more than 2 consonants appear next to each other. A vowel is usually followed by a consonant and a consonant is usually followed by another consonant or a vowel. The model seems to have followed this rule with a high percentage of the names it generated so I’m at least interpreting this as a good result.&lt;/p&gt;
&lt;p&gt;And the most fun part of this doing this project was to loudly laugh at the funny names in the dataset or the names my model predicted. So at the very least, having a good laugh was worth the time I spent on this :]&lt;/p&gt;
&lt;p&gt;If you’re curious about the implementation, head over to &lt;a href=&quot;https://github.com/aslisabanci/TurkishNameEngine&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;my repo on Github&lt;/a&gt; and check out the details✌️&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Enrolling in Andrew Ng's Deep Learning Specialization MOOC for free]]></title><description><![CDATA[This year, I enrolled in Andrew Ng's awesome Deep Learning Specialization series consisting of 5 different courses on Coursera; all for free. While chatting with people about this, I realized that people usually don't know to what extend you can make use of the course material when you enroll for free. So I wanted to share my experiences here and I hope it helps someone.]]></description><link>https://aslisabanci.github.io/blog/posts/enrolling-in-coursera-for-free</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/enrolling-in-coursera-for-free</guid><pubDate>Sun, 06 May 2018 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;This year, I enrolled in &lt;a href=&quot;http://deeplearning.ai&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Andrew Ng’s awesome Deep Learning Specialization series&lt;/a&gt; consisting of 5 different courses on Coursera; all for free. While chatting with people about this, I realized that people usually don’t know to what extend you can make use of the course material when you enroll for free. So I wanted to share my experiences here and I hope it helps someone.&lt;/p&gt;
&lt;h2 id=&quot;videos&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#videos&quot; aria-label=&quot;videos permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Videos&lt;/h2&gt;
&lt;p&gt;You have access to all the videos and their transcripts, even after the course ends.&lt;/p&gt;
&lt;h2 id=&quot;quizzes&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#quizzes&quot; aria-label=&quot;quizzes permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quizzes&lt;/h2&gt;
&lt;p&gt;You can submit your answers to the quizzes but you can’t see the correct answers and how well you did.&lt;/p&gt;
&lt;h2 id=&quot;projects&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#projects&quot; aria-label=&quot;projects permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h2&gt;
&lt;p&gt;You have all the access to the notebooks and all the files that the notebook requires to run properly. You can download these onto your local machine and run them locally if you wish too. (This was useful for me whenever I wanted to work on my projects at a time/place without any internet connection.)
You cannot access the project notebooks after the course ends though. So either finish your projects on time, or be prepared and download all the necessary files on your machine for later access.&lt;/p&gt;
&lt;h2 id=&quot;getting-graded&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#getting-graded&quot; aria-label=&quot;getting graded permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting graded&lt;/h2&gt;
&lt;p&gt;Of course you cannot submit your project notebooks and get graded. However, the team behind this MOOC has prepared all the notebooks in a way that they guide you and then they tell you the expected results of the step you’re implementing. Seeing the expected results after every step of your implementation is very helpful because you can spot your mistakes early instead of trying to understand what is wrong with your code; only at the end.&lt;/p&gt;
&lt;p&gt;So if you can get all the expected results with your implementation, you get your feedback that your solution gets the job done and you feel like you got a good grade :]&lt;/p&gt;
&lt;h2 id=&quot;certification&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#certification&quot; aria-label=&quot;certification permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Certification&lt;/h2&gt;
&lt;p&gt;Since you don’t get graded, you don’t expect to get a certificate either.&lt;/p&gt;
&lt;p&gt;So, to wrap up: If your only aim is to learn and experiment; enrolling for free can get you almost all the benefits in my opinion. The “expected results” on the notebooks give you the necessary feedback for your projects and you can get your hands on all the materials. If getting a certificate is not important for you; enrolling for free could you be your feasible solution to enjoy all this fantastic material.&lt;/p&gt;
&lt;p&gt;Don’t forget to praise this awesome course at every opportunity though :] because the effort behind all that material is huge and Andrew Ng is a great tutor in my opinion.&lt;/p&gt;
&lt;p&gt;Let me know if you have any questions and I’d be more than happy to help!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Kaggle Munich Meetup]]></title><description><![CDATA[Yesterday was my third week in Munich and to join the community of the city's machine learning peeps, I went to Kaggle Munich's meetup, held at the Google office.]]></description><link>https://aslisabanci.github.io/blog/posts/kaggle-munich-meetup</link><guid isPermaLink="false">https://aslisabanci.github.io/blog/posts/kaggle-munich-meetup</guid><pubDate>Sun, 06 May 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Yesterday was my third week in Munich and to join the community of the city’s machine learning peeps, I went to &lt;a href=&quot;https://www.meetup.com/Kaggle-Munich/events/past/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Kaggle Munich’s meetup&lt;/a&gt;, held at the Google office.&lt;/p&gt;
&lt;p&gt;The agenda was:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Listen to two talks&lt;/li&gt;
&lt;li&gt;Chat with people in the breaks&lt;/li&gt;
&lt;li&gt;Do some hands-on Kaggle hacking either by yourself, but preferably by creating a small team&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;talks&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#talks&quot; aria-label=&quot;talks permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Talks&lt;/h2&gt;
&lt;p&gt;The first talk was about the Vectorflow framework, which is a lightweight neural network framework implemented in the D language; and optimized for processing sparse data. Maybe someday I’ll get my hands on this while dabbling in a Kaggle competition - I’d like to see what advantages it would bring me.&lt;/p&gt;
&lt;p&gt;The second talk was about Hierarchical Temporal Memory, which is an experimental approach to machine learning where the neurons are different than the usual neural network neurons most of us are used to. This approach is inspired by our neocortex and it could have some advantages for certain types of problems. I don’t think I will get my hands on this in the short term, but still, it was interesting to learn about this new way of thinking. The slides of this talk are &lt;a href=&quot;https://github.com/ConnorJL/Kaggle-Munich-HTM&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;here on github&lt;/a&gt;, if you’d like to check them out.&lt;/p&gt;
&lt;h2 id=&quot;hands-on-kaggling&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#hands-on-kaggling&quot; aria-label=&quot;hands on kaggling permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hands on Kaggling&lt;/h2&gt;
&lt;p&gt;Although two of the talks were engaging, the most fun part of the meetup was the hands on Kaggle hacking session. I was curious about this &lt;a href=&quot;https://www.kaggle.com/c/avito-demand-prediction&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Avito Demand Prediction Challenge competition&lt;/a&gt; so I started a team, by acting as the noob seed and then we became a small team of three, when two other Kagglers joined me. We started by taking a look at the existing kernels and checked out some exploratory data analysis posts and some model implementations. We then submitted a super basic prediction output - just to have a baseline result to improve later on :]&lt;/p&gt;
&lt;h2 id=&quot;verdict&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#verdict&quot; aria-label=&quot;verdict permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Verdict😛&lt;/h2&gt;
&lt;p&gt;All in all, this was a super fun and friendly meetup. I am looking forward to the next one and I absolutely recommend it to you too, if you happen to be around Munich at that time and are keen to spend a good 3-4 hours thinking of and with data.&lt;/p&gt;</content:encoded></item></channel></rss>