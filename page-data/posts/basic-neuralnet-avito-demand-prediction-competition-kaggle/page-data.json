{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/basic-neuralnet-avito-demand-prediction-competition-kaggle","result":{"data":{"markdownRemark":{"id":"814f8d20-588e-55b3-ac19-4d974976e005","html":"<p>I wanted to try building a model for the Avito Demand Prediction competition on Kaggle and I came across a few hurdles on the road, which taught me lots of new things. I wasn’t after a good score but I just wanted to build a neural network with Keras from end to end and get predictions from it.</p>\n<p>So for this competition, we’re trying to predict demand for an online advertisement based on its full description (title, description, images, etc.) and its context.</p>\n<p>Roughly, I wanted to make use of the categorical features and a few continuous features. I also wanted to the features of the images and for this I wanted to get their extracted features from VGG16.</p>\n<h2 id=\"getting-image-features-from-vgg16\" style=\"position:relative;\"><a href=\"#getting-image-features-from-vgg16\" aria-label=\"getting image features from vgg16 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Getting image features from VGG16</h2>\n<p>While I was trying to get the image feature extraction through VGG16, I found out that someone else on Kaggle has a kernel for that, so I added his two kernels’ outputs (one outputting the VGG16 features of the training data set images and the other one, the test data set images) as the data source of my own kernel and I could use these sparse output matrices within my script.</p>\n<p>So I dropped the image column of the datasets and appended these 512 features taken from VGG16, to my train and test data frames (during feeding my model batch by batch, as explained below, because the dense array version of these sparse data was taking lots of memory).</p>\n<h2 id=\"cleaning-imputing-dropping-transforming-encoding-scaling\" style=\"position:relative;\"><a href=\"#cleaning-imputing-dropping-transforming-encoding-scaling\" aria-label=\"cleaning imputing dropping transforming encoding scaling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cleaning, imputing, dropping, transforming, encoding, scaling</h2>\n<p>I dropped the columns I won’t use and imputed the datasets by filling in the NAN values accordingly. Then I transformed some features like the activation date to weekday and title and description (which were in Russian) to their word counts (I could have dealt with this information by extracting the text features through another established model, but I didn’t focus on that).</p>\n<p>I encoded the categorical columns with LabelEncoders and I scaled my continuous features between 0 and 1, using the StandardScaler.</p>\n<h2 id=\"fitting-all-the-data-into-15gb-memory\" style=\"position:relative;\"><a href=\"#fitting-all-the-data-into-15gb-memory\" aria-label=\"fitting all the data into 15gb memory permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Fitting all the data into 15GB memory</h2>\n<p>Of course, as a noob, I took my chances to see if I can feed all of this data at once to my model. Apparently and indeed not surprisingly, this wasn’t possible with the Kaggle kernels’ 15 GB memory limit. Then I learnt about the fit_generator method of Keras, which lets you feed your data to your model, spoon by spoon :] I’m pretty happy that I learnt about this method - hurdles along the way are the best teachers I think.</p>\n<h2 id=\"getting-nan-loss-during-training\" style=\"position:relative;\"><a href=\"#getting-nan-loss-during-training\" aria-label=\"getting nan loss during training permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Getting NAN loss during training</h2>\n<p>During the initial steps, my loss value was decreasing but then I started getting NAN loss, before the 1st epoch completed. This made me suspicious of my input data and I found out that I forgot to scale some of my continuous features. I did that and these NAN values were gone.</p>\n<h2 id=\"final-thoughts\" style=\"position:relative;\"><a href=\"#final-thoughts\" aria-label=\"final thoughts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Final thoughts</h2>\n<p>So this pretty basic model didn’t do super great in the competition but I at least succeeded in building an end to end model, getting its predictions and I learnt a lot from these small to medium scale hurdles :]\nTo improve this, I can think of what new features I can introduce with “feature engineering”, modify my hyper-parameters or my network architecture or make use of some more features like the description for instance.</p>\n<p>So here is my script but of course it won’t run properly unless you run it on a Kaggle kernel by adding the necessary datasets. If you spot any mistakes, you are more than welcome to point those out and let me learn from you!</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> scipy <span class=\"token keyword\">import</span> sparse\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> StandardScaler\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Model\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>callbacks <span class=\"token keyword\">import</span> EarlyStopping<span class=\"token punctuation\">,</span> ModelCheckpoint\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Embedding<span class=\"token punctuation\">,</span> Dense<span class=\"token punctuation\">,</span> Input<span class=\"token punctuation\">,</span> concatenate<span class=\"token punctuation\">,</span> Flatten<span class=\"token punctuation\">,</span> Dropout<span class=\"token punctuation\">,</span> BatchNormalization\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>optimizers <span class=\"token keyword\">import</span> adam\n<span class=\"token keyword\">from</span> keras <span class=\"token keyword\">import</span> losses\n<span class=\"token keyword\">from</span> keras <span class=\"token keyword\">import</span> metrics\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">load_data</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\ttrain_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"../input/avito-demand-prediction/train.csv\"</span><span class=\"token punctuation\">,</span> parse_dates<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"activation_date\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ttest_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"../input/avito-demand-prediction/test.csv\"</span><span class=\"token punctuation\">,</span> parse_dates<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"activation_date\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'activation_date'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>\n\t\tpd<span class=\"token punctuation\">.</span>to_datetime<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">[</span><span class=\"token string\">'activation_date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>weekday<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>int32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'activation_date'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>\n\t\tpd<span class=\"token punctuation\">.</span>to_datetime<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">[</span><span class=\"token string\">'activation_date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>weekday<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>int32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n\ty_col <span class=\"token operator\">=</span> <span class=\"token string\">'deal_probability'</span>\n\n\t<span class=\"token keyword\">return</span> train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">,</span> y_col\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">fill_na</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'image_top_1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token number\">3067</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'image_top_1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token number\">3067</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'param_1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token string\">'_NA_'</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'param_1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token string\">'_NA_'</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'param_2'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token string\">'_NA_'</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'param_2'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token string\">'_NA_'</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'param_3'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token string\">'_NA_'</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'param_3'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>value<span class=\"token operator\">=</span><span class=\"token string\">'_NA_'</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">return</span> train_data<span class=\"token punctuation\">,</span> test_data\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">drop_unwanted</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\ttrain_data<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'item_id'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'user_id'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'image'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'item_id'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'user_id'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'image'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">return</span> train_data<span class=\"token punctuation\">,</span> test_data\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">encode_cat_columns</span><span class=\"token punctuation\">(</span>all_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\tcat_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'region'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'parent_category_name'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'category_name'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'city'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'user_type'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'image_top_1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'param_1'</span><span class=\"token punctuation\">,</span>\n\t            <span class=\"token string\">'param_2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'param_3'</span><span class=\"token punctuation\">]</span>\n\n\tle_encoders <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>x<span class=\"token punctuation\">:</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> cat_cols<span class=\"token punctuation\">}</span>\n\tlabel_enc_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>k<span class=\"token punctuation\">:</span> v<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>all_data<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> le_encoders<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n\n\t<span class=\"token keyword\">return</span> le_encoders<span class=\"token punctuation\">,</span> label_enc_cols\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">transform_title_description</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">.</span>description<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test_data<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test_data<span class=\"token punctuation\">.</span>description<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">return</span> train_data<span class=\"token punctuation\">,</span> test_data\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">scale_num_cols</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\tstdScaler <span class=\"token operator\">=</span> StandardScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ttrain_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> stdScaler<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ttest_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> stdScaler<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">return</span> train_data<span class=\"token punctuation\">,</span> test_data\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">load_VGG16_img_features</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\ttrain_img_features <span class=\"token operator\">=</span> sparse<span class=\"token punctuation\">.</span>load_npz<span class=\"token punctuation\">(</span><span class=\"token string\">'../input/vgg16-train-features/features.npz'</span><span class=\"token punctuation\">)</span>\n\ttest_img_features <span class=\"token operator\">=</span> sparse<span class=\"token punctuation\">.</span>load_npz<span class=\"token punctuation\">(</span><span class=\"token string\">'../input/vgg16-test-features/features.npz'</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">return</span> train_img_features<span class=\"token punctuation\">,</span> test_img_features\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">split_train_validation</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\tval_split <span class=\"token operator\">=</span> <span class=\"token number\">0.15</span>\n\tval_ix <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>rint<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> <span class=\"token operator\">-</span> val_split<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\tt_split_df <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>val_ix<span class=\"token punctuation\">]</span>\n\tv_split_df <span class=\"token operator\">=</span> train_data<span class=\"token punctuation\">[</span>val_ix<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n\n\timage_t_split_df <span class=\"token operator\">=</span> train_img_features<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>val_ix<span class=\"token punctuation\">]</span>\n\timage_v_split_df <span class=\"token operator\">=</span> train_img_features<span class=\"token punctuation\">[</span>val_ix<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n\n\t<span class=\"token keyword\">return</span> t_split_df<span class=\"token punctuation\">,</span> v_split_df<span class=\"token punctuation\">,</span> image_t_split_df<span class=\"token punctuation\">,</span> image_v_split_df\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">gen_samples</span><span class=\"token punctuation\">(</span>in_df<span class=\"token punctuation\">,</span> img_df<span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> loss_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n\tsamples_per_epoch <span class=\"token operator\">=</span> in_df<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\tnumber_of_batches <span class=\"token operator\">=</span> samples_per_epoch <span class=\"token operator\">/</span> batch_size\n\tcounter <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n\t<span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n\n\t\t<span class=\"token keyword\">if</span> batch_size <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n\t\t\tout_df <span class=\"token operator\">=</span> in_df\n\n\t\t<span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n\t\t\tsub_img_frame <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>img_df<span class=\"token punctuation\">[</span>batch_size <span class=\"token operator\">*</span> counter<span class=\"token punctuation\">:</span>batch_size <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>counter <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>todense<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\t\t\tsub_img_frame<span class=\"token punctuation\">.</span>columns <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'img_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> sub_img_frame<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">]</span>\n\n\t\t\tout_df <span class=\"token operator\">=</span> in_df<span class=\"token punctuation\">[</span>batch_size <span class=\"token operator\">*</span> counter<span class=\"token punctuation\">:</span>batch_size <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>counter <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n\t\t\t<span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> sub_img_frame<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">:</span>\n\t\t\t\tout_df<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>out_df<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>sub_img_frame<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span>out_df<span class=\"token punctuation\">.</span>index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\t\tfeed_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>col_name<span class=\"token punctuation\">:</span> le_encoders<span class=\"token punctuation\">[</span>col_name<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>out_df<span class=\"token punctuation\">[</span>col_name<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> col_name <span class=\"token keyword\">in</span> cat_cols<span class=\"token punctuation\">}</span>\n\n\t\tcont_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>x <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> out_df<span class=\"token punctuation\">.</span>columns <span class=\"token keyword\">if</span> <span class=\"token string\">'img_'</span> <span class=\"token keyword\">in</span> x<span class=\"token punctuation\">]</span>\n\t\tcont_cols<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item_seq_number'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'description'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t\tfeed_dict<span class=\"token punctuation\">[</span><span class=\"token string\">'continuous'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> out_df<span class=\"token punctuation\">[</span>cont_cols<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>values\n\n\t\tcounter <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n\n\t\t<span class=\"token keyword\">yield</span> feed_dict<span class=\"token punctuation\">,</span> out_df<span class=\"token punctuation\">[</span>loss_name<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>values\n\n\t\t<span class=\"token keyword\">if</span> counter <span class=\"token operator\">&lt;=</span> number_of_batches<span class=\"token punctuation\">:</span>\n\t\t\tcounter <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">root_mean_squared_error</span><span class=\"token punctuation\">(</span>y_true<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t<span class=\"token keyword\">return</span> K<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>K<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>K<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>y_pred <span class=\"token operator\">-</span> y_true<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">build_model</span><span class=\"token punctuation\">(</span>label_enc_cols<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\tall_embeddings<span class=\"token punctuation\">,</span> all_inputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n\t<span class=\"token keyword\">for</span> key<span class=\"token punctuation\">,</span> val <span class=\"token keyword\">in</span> label_enc_cols<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t\tin_val <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> key<span class=\"token punctuation\">)</span>\n\t\tall_embeddings <span class=\"token operator\">+=</span> <span class=\"token punctuation\">[</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>Embedding<span class=\"token punctuation\">(</span>val<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>val<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>in_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\t\tall_inputs <span class=\"token operator\">+=</span> <span class=\"token punctuation\">[</span>in_val<span class=\"token punctuation\">]</span>\n\n\tconcat_emb_layer <span class=\"token operator\">=</span> concatenate<span class=\"token punctuation\">(</span>all_embeddings<span class=\"token punctuation\">)</span>\n\tbn_emb <span class=\"token operator\">=</span> BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>concat_emb_layer<span class=\"token punctuation\">)</span>\n\temb_layer <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>bn_emb<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\tcont_input <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">516</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'continuous'</span><span class=\"token punctuation\">)</span>\n\tbn_cont <span class=\"token operator\">=</span> BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>cont_input<span class=\"token punctuation\">)</span>\n\tcont_feature_layer <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>bn_cont<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\tfull_concat_layer <span class=\"token operator\">=</span> concatenate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>emb_layer<span class=\"token punctuation\">,</span> cont_feature_layer<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\tfull_reduction <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>full_concat_layer<span class=\"token punctuation\">)</span>\n\n\tout_layer <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>full_reduction<span class=\"token punctuation\">)</span>\n\tmodel <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>inputs <span class=\"token operator\">=</span> all_inputs <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>cont_input<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> outputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>out_layer<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\t<span class=\"token keyword\">return</span> model\n\n\n\ntrain_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">,</span> y_col <span class=\"token operator\">=</span> load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain_data<span class=\"token punctuation\">,</span> test_data <span class=\"token operator\">=</span> fill_na<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span>\ntrain_data<span class=\"token punctuation\">,</span> test_data <span class=\"token operator\">=</span> drop_unwanted<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span>\ntrain_data<span class=\"token punctuation\">,</span> test_data <span class=\"token operator\">=</span> transform_title_description<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span>\n\nall_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> sort <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nle_encoders<span class=\"token punctuation\">,</span> label_enc_cols <span class=\"token operator\">=</span> encode_cat_columns<span class=\"token punctuation\">(</span>all_data<span class=\"token punctuation\">)</span>\n\ntrain_data<span class=\"token punctuation\">,</span> test_data <span class=\"token operator\">=</span> scale_num_cols<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">)</span>\n\ntrain_img_features<span class=\"token punctuation\">,</span> test_img_features <span class=\"token operator\">=</span> load_VGG16_img_features<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nt_split_df<span class=\"token punctuation\">,</span> v_split_df<span class=\"token punctuation\">,</span> image_t_split_df<span class=\"token punctuation\">,</span> image_v_split_df <span class=\"token operator\">=</span> split_train_validation<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> build_model<span class=\"token punctuation\">(</span>label_enc_cols<span class=\"token punctuation\">)</span>\n\noptimizer <span class=\"token operator\">=</span> optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>lr <span class=\"token operator\">=</span> <span class=\"token number\">0.0005</span><span class=\"token punctuation\">,</span> beta_1 <span class=\"token operator\">=</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span> beta_2 <span class=\"token operator\">=</span> <span class=\"token number\">0.999</span><span class=\"token punctuation\">,</span> epsilon <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> decay <span class=\"token operator\">=</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span> amsgrad <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> root_mean_squared_error<span class=\"token punctuation\">,</span> metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>root_mean_squared_error<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ncheckpoint <span class=\"token operator\">=</span> ModelCheckpoint<span class=\"token punctuation\">(</span><span class=\"token string\">'best_weights.hdf5'</span><span class=\"token punctuation\">,</span> monitor <span class=\"token operator\">=</span> <span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">,</span> verbose <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> save_best_only <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nearly <span class=\"token operator\">=</span> EarlyStopping<span class=\"token punctuation\">(</span>patience <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> mode <span class=\"token operator\">=</span> <span class=\"token string\">'min'</span><span class=\"token punctuation\">)</span>\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\nmodel<span class=\"token punctuation\">.</span>fit_generator<span class=\"token punctuation\">(</span>gen_samples<span class=\"token punctuation\">(</span>t_split_df<span class=\"token punctuation\">,</span> image_t_split_df<span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> y_col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    epochs <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                    steps_per_epoch <span class=\"token operator\">=</span> t_split_df<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> batch_size<span class=\"token punctuation\">,</span>\n                    validation_data <span class=\"token operator\">=</span> <span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span>gen_samples<span class=\"token punctuation\">(</span>v_split_df<span class=\"token punctuation\">,</span> image_v_split_df<span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span> y_col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    validation_steps <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n                    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>checkpoint<span class=\"token punctuation\">,</span> early<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ntest_vars<span class=\"token punctuation\">,</span> test_id <span class=\"token operator\">=</span> <span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span>gen_samples<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">,</span> test_img_features<span class=\"token punctuation\">,</span> test_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> loss_name <span class=\"token operator\">=</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>load_weights<span class=\"token punctuation\">(</span><span class=\"token string\">'best_weights.hdf5'</span><span class=\"token punctuation\">)</span>\npreds <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>test_vars<span class=\"token punctuation\">)</span>\n\nsubm <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"../input/avito-demand-prediction/sample_submission.csv\"</span><span class=\"token punctuation\">)</span>\nsubm<span class=\"token punctuation\">[</span><span class=\"token string\">'deal_probability'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> preds\nsubm<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'submission_adam.csv'</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></code></pre></div>","fields":{"slug":"/posts/basic-neuralnet-avito-demand-prediction-competition-kaggle","tagSlugs":["/tag/kaggle/","/tag/deep-learning/"]},"frontmatter":{"date":"2018-28-06T22:12:03.284Z","description":"I wanted to try building a model for the Avito Demand Prediction competition on Kaggle and I came across a few hurdles on the road, which taught me lots of new things. I wasn't after a good score but I just wanted to build a neural network with Keras from end to end and get predictions from it.","tags":["kaggle","deep-learning"],"title":"Basic NN for the Avito Demand Prediction Competition on Kaggle","socialImage":{"publicURL":"/blog/static/551bbf738819bfac5bae4b8421db4fc7/thumbnail-kaggle.png"}}}},"pageContext":{"slug":"/posts/basic-neuralnet-avito-demand-prediction-competition-kaggle"}},"staticQueryHashes":["251939775","401334301","4120999787"]}